{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/\n",
    "#https://huggingface.co/docs/tokenizers/pipeline\n",
    "#https://stackoverflow.com/questions/41912083/nltk-tokenize-faster-way\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "#https://www.nltk.org/howto/wordnet.html\n",
    "#https://subscription.packtpub.com/book/data/9781782167853/1/ch01lvl1sec15/looking-up-lemmas-and-synonyms-in-wordnet\n",
    "#https://www.kaggle.com/code/roblexnana/nlp-with-nltk-tokenizing-text-and-wordnet-basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/marilu/training_dfs/feeling_thinking.csv',\n",
       " '/home/marilu/training_dfs/judging_perceiving.csv',\n",
       " '/home/marilu/training_dfs/nationality.csv',\n",
       " '/home/marilu/training_dfs/gender.csv',\n",
       " '/home/marilu/training_dfs/birth_year.csv',\n",
       " '/home/marilu/training_dfs/sensing_intuitive.csv',\n",
       " '/home/marilu/training_dfs/extrovert_introvert.csv',\n",
       " '/home/marilu/training_dfs/political_leaning.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs = list(set(glob('/home/marilu/training_dfs/*.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*_ft.csv')) - \n",
    "                 set(glob('/home/marilu/training_dfs/*balanced.csv')))\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auhtor_ID</th>\n",
       "      <th>post</th>\n",
       "      <th>political_leaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>You can \"buy\" the show and stream it through t...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>me want to play Q*bert Holy shit, based Alex J...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>Shouldn't rely on any external services or per...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>PR to a specific person. Usually that just mea...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t2_7ramzeng</td>\n",
       "      <td>This article's intention is clear that they wa...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114458</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>hard as I have to go out of my way to find med...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114459</th>\n",
       "      <td>t2_vi35s</td>\n",
       "      <td>WORLD WILL BE MINE! Well if you read it, then ...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114460</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>Wow super passing there sir. I’m jelly. Aesthe...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114461</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>compliment your face. Okay fair enough. I supp...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114462</th>\n",
       "      <td>t2_vyu81f9</td>\n",
       "      <td>and try to live yours lest you spend it all wa...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114463 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          auhtor_ID                                               post  \\\n",
       "0       t2_7ramzeng  You can \"buy\" the show and stream it through t...   \n",
       "1       t2_7ramzeng  me want to play Q*bert Holy shit, based Alex J...   \n",
       "2       t2_7ramzeng  Shouldn't rely on any external services or per...   \n",
       "3       t2_7ramzeng  PR to a specific person. Usually that just mea...   \n",
       "4       t2_7ramzeng  This article's intention is clear that they wa...   \n",
       "...             ...                                                ...   \n",
       "114458     t2_vi35s  hard as I have to go out of my way to find med...   \n",
       "114459     t2_vi35s  WORLD WILL BE MINE! Well if you read it, then ...   \n",
       "114460   t2_vyu81f9  Wow super passing there sir. I’m jelly. Aesthe...   \n",
       "114461   t2_vyu81f9  compliment your face. Okay fair enough. I supp...   \n",
       "114462   t2_vyu81f9  and try to live yours lest you spend it all wa...   \n",
       "\n",
       "       political_leaning  \n",
       "0                  right  \n",
       "1                  right  \n",
       "2                  right  \n",
       "3                  right  \n",
       "4                  right  \n",
       "...                  ...  \n",
       "114458            center  \n",
       "114459            center  \n",
       "114460              left  \n",
       "114461              left  \n",
       "114462              left  \n",
       "\n",
       "[114463 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dirs[7]) #fill in the number of political leaning\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "X_post = vec.fit_transform(data['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_political = data['political_leaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_post, y_political, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.77      0.71     14160\n",
      "        left       0.69      0.61      0.65      9625\n",
      "       right       0.73      0.63      0.68     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.69      0.67      0.68     34339\n",
      "weighted avg       0.69      0.68      0.68     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_synonyms(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        syns = wordnet.synsets(token)\n",
    "        if syns:\n",
    "            synonym = syns[0].lemmas()[0].name()\n",
    "            new_tokens.append(synonym)\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    return ' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated_data['paraphrased_post'] = data['post'].apply(replace_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paraphrased = obfuscated_data['paraphrased_post']\n",
    "y_paraphrased = obfuscated_data['political_leaning']\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_paraphrased, y_paraphrased, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_paraphrased = TfidfVectorizer()\n",
    "X_train_vec_p = vec_paraphrased.fit_transform(X_train_p)\n",
    "X_test_vec_p = vec_paraphrased.transform(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=6000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_p = LogisticRegression(max_iter=6000)\n",
    "classifier_p.fit(X_train_vec_p, y_train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_p = classifier_p.predict(X_test_vec_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for paraphrased posts:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.65      0.76      0.70     14160\n",
      "        left       0.68      0.61      0.64      9625\n",
      "       right       0.72      0.63      0.67     10554\n",
      "\n",
      "    accuracy                           0.68     34339\n",
      "   macro avg       0.68      0.66      0.67     34339\n",
      "weighted avg       0.68      0.68      0.67     34339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for paraphrased posts:\")\n",
    "print(classification_report(y_test_p, predictions_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         You can `` bargain '' the show and stream info...\n",
       "1         Maine privation to play Q * bert holy_place cr...\n",
       "2         Should n't trust on any external services Oreg...\n",
       "3         praseodymium to angstrom particular person . n...\n",
       "4         This article 's purpose be clear that they pri...\n",
       "                                ...                        \n",
       "114458    difficult arsenic iodine rich_person to go out...\n",
       "114459    universe volition beryllium mine ! well if you...\n",
       "114460    belly_laugh superintendent pass there sir . io...\n",
       "114461    compliment your face . O.K. carnival enough . ...\n",
       "114462    and attempt to populate yours fifty you spend ...\n",
       "Name: paraphrased_post, Length: 114463, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_paraphrased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
